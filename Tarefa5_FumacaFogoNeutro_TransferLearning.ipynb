{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Tarefa5_FumacaFogoNeutro_TransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonasfelipe22/DLVC/blob/main/Tarefa5_FumacaFogoNeutro_TransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jMG8Lrgd4on"
      },
      "source": [
        "# Tarefa 5\n",
        "\n",
        "Nesta tarefa, utilizaremos novamente o banco de imagens para detecção de fumaça e fogo. \n",
        "\n",
        "Desta vez, vamos usar Transfer Learning para melhorar o desempenho do classificador. \n",
        "\n",
        "O dataset foi disponibilizado por [Kaiming H. et al, Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385 ). \n",
        "\n",
        "Os arquivos estão dispostos na mesma estrutura da Tarefa 4. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NFuMFYXtwsT",
        "outputId": "2403dd3b-d976-42c7-929f-787baa68bdae"
      },
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import os\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras import regularizers, optimizers\n",
        "\n",
        "DESIRED_ACCURACY = 0.99\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    \"https://github.com/DeepQuestAI/Fire-Smoke-Dataset/releases/download/v1/FIRE-SMOKE-DATASET.zip\" -O \"/tmp/fire-smoke.zip\"\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/tmp/fire-smoke.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/\")\n",
        "zip_ref.close()\n",
        "\n",
        "# Conjunto Fumaça-Fogo\n",
        "!mkdir -p /tmp/S-F/{Train,Test}/\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Smoke\" \"/tmp/S-F/Train/Smoke\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Smoke\" \"/tmp/S-F/Test/Smoke\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Fire\" \"/tmp/S-F/Train/Fire\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Fire\" \"/tmp/S-F/Test/Fire\"\n",
        "\n",
        "# Conjunto Neutro-Fogo\n",
        "!mkdir -p /tmp/N-F/{Train,Test}/\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Neutral\" \"/tmp/N-F/Train/Neutral\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Neutral\" \"/tmp/N-F/Test/Neutral\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Fire\" \"/tmp/N-F/Train/Fire\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Fire\" \"/tmp/N-F/Test/Fire\"\n",
        "\n",
        "# Conjunto Neutro-Fumaça\n",
        "!mkdir -p /tmp/N-S/{Train,Test}/\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Neutral\" \"/tmp/N-S/Train/Neutral\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Neutral\" \"/tmp/N-S/Test/Neutral\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Train/Smoke\" \"/tmp/N-S/Train/Smoke\"\n",
        "!ln -sf \"/tmp/FIRE-SMOKE-DATASET/Test/Smoke\" \"/tmp/N-S/Test/Smoke\"\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-09 01:03:57--  https://github.com/DeepQuestAI/Fire-Smoke-Dataset/releases/download/v1/FIRE-SMOKE-DATASET.zip\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/193940929/09220a00-9842-11e9-8756-2d8df8631bb5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211109%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211109T010357Z&X-Amz-Expires=300&X-Amz-Signature=7c979f64e633a31676b45298eb39505a733683f367fa0de4222c245f402d88c7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=193940929&response-content-disposition=attachment%3B%20filename%3DFIRE-SMOKE-DATASET.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-11-09 01:03:57--  https://github-releases.githubusercontent.com/193940929/09220a00-9842-11e9-8756-2d8df8631bb5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211109%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211109T010357Z&X-Amz-Expires=300&X-Amz-Signature=7c979f64e633a31676b45298eb39505a733683f367fa0de4222c245f402d88c7&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=193940929&response-content-disposition=attachment%3B%20filename%3DFIRE-SMOKE-DATASET.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 320963592 (306M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/fire-smoke.zip’\n",
            "\n",
            "/tmp/fire-smoke.zip 100%[===================>] 306.09M  30.8MB/s    in 11s     \n",
            "\n",
            "2021-11-09 01:04:08 (29.0 MB/s) - ‘/tmp/fire-smoke.zip’ saved [320963592/320963592]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIET52LYfk9Y"
      },
      "source": [
        "O conjunto Neutro-Fogo está no diretório `/tmp/N-F/` e o conjunto Neutro-Fumaça está em `/tmp/N-S/`. \n",
        "\n",
        "O conjunto completo (com as três classes, Neutro, Fumaça e Fogo) está em `/tmp/FIRE-SMOKE/DATASET/`. \n",
        "\n",
        "Cada conjunto tem 2 subconjuntos: `Train` e `Test` para treinamento e validação, respectivamente. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEDvwgLzgLvN"
      },
      "source": [
        "## Questões\n",
        "\n",
        "1. Crie 2 modelos, um para o conjunto N-F e outro para o conjunto N-S. Através de TransferLearning, utilize parte da rede pré-treinada da InceptionV3 (conforme a Lição 9). Avalie o desempenho (acurácia e perdas no treinamento e validação). \n",
        "\n",
        "2. Desenvolva um classificador categórico, com a InceptionV3, para discriminar os 3 tipos de imagem: Neutro, Fumaça e Fogo. Avalie o desempenho. Você deverá modificar alguns pontos na sua rede, para que o classificador seja categórico: (i) flow_from_directory, (ii) função de perda e (iii) número de neurônios na camada de saída. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pqn3za8n72E"
      },
      "source": [
        "base_dir = '/tmp/N-F'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "validation_dir = os.path.join(base_dir, 'Test')\n",
        "\n",
        "\n",
        "train_Fire_dir = os.path.join(train_dir, 'Fire')\n",
        "train_Neutral_dir = os.path.join(train_dir, 'Neutral')\n",
        "\n",
        "\n",
        "validation_Fire_dir = os.path.join(validation_dir, 'Fire')\n",
        "validation_Neutral_dir = os.path.join(validation_dir, 'Neutral')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro6LTagBn7ly",
        "outputId": "a7bc2f10-406f-4fc9-d2cc-48016ce28f63"
      },
      "source": [
        "weight_decay = 1e-4 \n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# This code has changed. Now instead of the ImageGenerator just rescaling\n",
        "# the image, we also rotate and do other operations\n",
        "# Updated to do image augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    steps_per_epoch=90,\n",
        "                    epochs=15,\n",
        "                    validation_steps=10,\n",
        "                    verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1800 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n",
            "Epoch 1/15\n",
            "90/90 - 50s - loss: 0.6219 - accuracy: 0.7811 - val_loss: 1.1869 - val_accuracy: 0.5000\n",
            "Epoch 2/15\n",
            "90/90 - 18s - loss: 0.4799 - accuracy: 0.8478 - val_loss: 1.8127 - val_accuracy: 0.5000\n",
            "Epoch 3/15\n",
            "90/90 - 18s - loss: 0.4303 - accuracy: 0.8661 - val_loss: 2.0507 - val_accuracy: 0.5150\n",
            "Epoch 4/15\n",
            "90/90 - 18s - loss: 0.3927 - accuracy: 0.8672 - val_loss: 1.0752 - val_accuracy: 0.6900\n",
            "Epoch 5/15\n",
            "90/90 - 18s - loss: 0.3569 - accuracy: 0.8828 - val_loss: 0.4528 - val_accuracy: 0.8250\n",
            "Epoch 6/15\n",
            "90/90 - 18s - loss: 0.3340 - accuracy: 0.8939 - val_loss: 0.4975 - val_accuracy: 0.8500\n",
            "Epoch 7/15\n",
            "90/90 - 18s - loss: 0.3085 - accuracy: 0.8900 - val_loss: 0.4695 - val_accuracy: 0.8950\n",
            "Epoch 8/15\n",
            "90/90 - 18s - loss: 0.2973 - accuracy: 0.9072 - val_loss: 0.5559 - val_accuracy: 0.8550\n",
            "Epoch 9/15\n",
            "90/90 - 18s - loss: 0.2773 - accuracy: 0.9139 - val_loss: 0.4989 - val_accuracy: 0.9000\n",
            "Epoch 10/15\n",
            "90/90 - 18s - loss: 0.2844 - accuracy: 0.9056 - val_loss: 0.5213 - val_accuracy: 0.8600\n",
            "Epoch 11/15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pcb94N4qHGn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPbuLcpXuKng"
      },
      "source": [
        "base_dir = '/tmp/N-S'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "validation_dir = os.path.join(base_dir, 'Test')\n",
        "\n",
        "\n",
        "train_Fire_dir = os.path.join(train_dir, 'Smoke')\n",
        "train_Neutral_dir = os.path.join(train_dir, 'Neutral')\n",
        "\n",
        "\n",
        "validation_Fire_dir = os.path.join(validation_dir, 'Smoke')\n",
        "validation_Neutral_dir = os.path.join(validation_dir, 'Neutral')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rWKAxUNug8c"
      },
      "source": [
        "weight_decay = 1e-4 \n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay), input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_regularizer=regularizers.l2(weight_decay)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# This code has changed. Now instead of the ImageGenerator just rescaling\n",
        "# the image, we also rotate and do other operations\n",
        "# Updated to do image augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(150, 150),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "history = model.fit(train_generator,\n",
        "                    validation_data=validation_generator,\n",
        "                    steps_per_epoch=90,\n",
        "                    epochs=15,\n",
        "                    validation_steps=10,\n",
        "                    verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GKaRAr-u8Au"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emqot7qx0MJ_"
      },
      "source": [
        "base_dir = '/tmp/N-F'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "validation_dir = os.path.join(base_dir, 'Test')\n",
        "\n",
        "\n",
        "train_Fire_dir = os.path.join(train_dir, 'Fire')\n",
        "train_Neutral_dir = os.path.join(train_dir, 'Neutral')\n",
        "\n",
        "\n",
        "validation_Fire_dir = os.path.join(validation_dir, 'Fire')\n",
        "validation_Neutral_dir = os.path.join(validation_dir, 'Neutral')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oktQn6PhyClS"
      },
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxOu2ZKdzhJt"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQVyM8Y7z41K"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVXK-vnI0WgX"
      },
      "source": [
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 90,\n",
        "            epochs = 20,\n",
        "            validation_steps = 10,\n",
        "            verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNgFer8G0gKO"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rj5syz71Arv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm4htwAN04Dv"
      },
      "source": [
        "base_dir = '/tmp/N-S'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "validation_dir = os.path.join(base_dir, 'Test')\n",
        "\n",
        "\n",
        "train_Fire_dir = os.path.join(train_dir, 'Smoke')\n",
        "train_Neutral_dir = os.path.join(train_dir, 'Neutral')\n",
        "\n",
        "\n",
        "validation_Fire_dir = os.path.join(validation_dir, 'Smoke')\n",
        "validation_Neutral_dir = os.path.join(validation_dir, 'Neutral')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02eE7fhp04Dx"
      },
      "source": [
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls-pfEFF04Dy"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHWyEWIV04D1"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHc_n_nA04D2"
      },
      "source": [
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 90,\n",
        "            epochs = 20,\n",
        "            validation_steps = 10,\n",
        "            verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u-UZqUg04D3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}